# 윤원희 - 경력기술서 (Career Portfolio)

**Backend Developer | 7 Years Experience**

---

## 개인 정보

- **이름:** 윤원희
- **직무:** Backend Developer (7년 차)
- **이메일:** wony9324@naver.com
- **전화번호:** 010-3555-2320
- **GitHub:** https://github.com/younwony

---

## Professional Summary

**"비즈니스 임팩트를 숫자로 증명하는 데이터 드리븐 개발자"**

7년 간 커머스 및 마케팅 도메인에서 대용량 트래픽 처리와 시스템 자동화에 주력해 왔습니다. Java/Spring Boot 기반의 안정적인 시스템 구축 역량을 바탕으로, **Elasticsearch 도입으로 검색 성능을 20배 개선**하고, **ThreadPoolTaskExecutor 커스터마이징과 병렬 처리 아키텍처 설계로 데이터 수집 속도를 100배(100명/h → 10,000명/h) 단축**한 경험이 있습니다. 단순한 기능 구현을 넘어, 운영 비효율을 제거하는 자동화 시스템 구축을 통해 조직의 생산성을 높이는 데 기여합니다.

---

## Core Competencies

- **Architecture & Performance:** 대용량 데이터 처리를 위한 병렬 아키텍처 설계 및 ThreadPoolTaskExecutor 최적화 경험
- **Data Pipeline:** 200만 건 이상의 이기종 데이터 수집·정제·적재(ETL) 파이프라인 구축
- **Search Engine:** Elasticsearch 기반의 검색 엔진 도입 및 인덱싱 최적화 (성능 20배 개선)
- **Resilience Engineering:** Resilience4j RateLimiter 및 Backoff Retry 정책을 통한 API 안정성 확보
- **Automation:** 운영 비효율 제거를 위한 업무 프로세스 100% 자동화 (Zero Ops 지향)

---

## Technical Skills

### Languages & Frameworks
- **Java (Expert)**, Spring Boot, Spring Batch, JPA/Hibernate

### Database & Cache
- MySQL, Oracle, **Redis (Distributed Lock)**, **Elasticsearch**

### Infra & DevOps
- AWS (EC2, S3, RDS), Docker, Jenkins, GitHub Actions

### Tools & Libraries
- IntelliJ, JIRA, Confluence, **Resilience4j**, Slack API, GA4, BigQuery

---

## Detailed Work Experience

### (주)구하다
**Backend Developer (Senior)**
**기간:** 2022.02 - 재직 중 (3년 9개월)
**부서:** Tech 팀

---

## 프로젝트 1: 인플루언서 데이터 플랫폼 고도화 (200만 데이터 규모)

### 📌 Situation (배경)

**비즈니스 제약**
- 기존 단일 스레드 기반 수집기로는 시간당 처리량이 **100건**에 불과해 캠페인 확장이 불가능했음
- 마케팅팀이 틱톡/인스타그램을 직접 탐색하고 엑셀(Excel)에 수기로 입력하여 관리함에 따라 인적 리소스 한계 및 데이터 최신성 유지 불가

**기술적 제약**
- 외부 API(TikTok 등)의 엄격한 **Rate Limit**으로 인해 무작정 요청을 늘릴 수 없는 상황
- CDN 링크 만료로 인한 이미지 유실 문제로 데이터 정합성 유지 어려움

### 🎯 Task (과제/목표)

**비즈니스 목표**
- API 차단 없이 데이터 수집 속도를 기존 대비 **100배(10,000건/h)** 이상으로 끌어올려야 함
- CDN 링크 만료로 인한 이미지 유실을 **0%**로 만들어 데이터 정합성을 확보해야 함

**기술적 목표**
- 멀티 인스턴스 환경에서 중복 수집 방지
- 200만 건 규모의 실시간 검색 및 분석 기능 제공

### ⚡ Action (해결 방법)

**1. 병렬 아키텍처 설계**

**ThreadPoolTaskExecutor 커스터마이징**
- **의사결정 배경:** 단일 스레드 방식으로는 I/O 대기 시간이 대부분이어서 리소스를 효율적으로 활용하지 못함. 병렬 처리를 통해 I/O Blocking 시간 동안 다른 작업을 수행하도록 설계
- **구현 내용:**
  - ThreadPoolTaskExecutor의 CorePoolSize, MaxPoolSize, QueueCapacity를 튜닝하여 최적 성능 달성
  - I/O Bound 작업 특성을 고려하여 스레드 풀 사이즈를 CPU 코어 수의 2배로 설정
  - RejectedExecutionHandler를 커스터마이징하여 대기열 초과 시 재시도 로직 구현
- **성과:** 동시 처리 수를 100배 증가시켜 시간당 **10,000건** 수집 달성

**2. 안정성 확보 전략**

**Resilience4j RateLimiter와 Backoff Retry 정책**
- **의사결정 배경:** 외부 API의 Rate Limit을 초과하면 IP 차단 위험이 있어, API 임계치 내에서 최대 효율을 내는 것이 핵심
- **구현 내용:**
  - Resilience4j RateLimiter를 적용하여 API 호출 속도를 제한 (예: 초당 100건)
  - Exponential Backoff Retry 정책으로 실패 시 대기 시간을 점진적으로 증가 (1초 → 2초 → 4초...)
  - Circuit Breaker 패턴으로 연속 실패 시 일정 시간 동안 API 호출 중단하여 시스템 보호
- **성과:** API 차단 **0건** 달성, 안정적인 수집 환경 구축

**3. 분산 제어**

**Redis Distributed Lock 도입**
- **의사결정 배경:** 멀티 인스턴스 환경에서 동일 인플루언서를 중복 수집하면 API 호출 낭비 및 데이터 정합성 문제 발생
- **구현 내용:**
  - Redisson 라이브러리의 RLock을 활용하여 인플루언서 ID를 키로 하는 분산 락 구현
  - Lock Timeout과 Lease Time을 적절히 설정하여 데드락 방지
  - Lock 획득 실패 시 Skip 정책으로 다른 인스턴스의 작업과 충돌 방지
- **성과:** 중복 수집 **0%** 달성

**4. 검색 성능 최적화**

**Elasticsearch 기반 실시간 검색 엔진 구축**
- **의사결정 배경:** RDB는 복합 조건 검색(플랫폼, 팔로워 수, 지역 등)에 한계가 있어 Elasticsearch의 역색인 구조를 활용하기로 결정
- **구현 내용:**
  - 200만 건 데이터에 대한 인덱싱 설계 (플랫폼, 팔로워 수, 지역, 카테고리 등)
  - Term, Range, Match 쿼리를 조합한 복합 검색 구현
  - Shard와 Replica 설정을 최적화하여 검색 성능 극대화
- **성과:** 복합 조건 검색 **200ms 이내** 처리, 검색 성능 **20배 개선**

### ✅ Result (성과)

**비즈니스 임팩트**
- 수집 속도 **99% 단축 (100명/h → 10,000명/h)**
- 데이터 풀 **20배 확대 (10만 → 200만 명)**로 마케팅 커버리지 극대화
- 리포팅 작업 완전 자동화로 운영팀 수작업 제거

**기술적 성과**
- API 차단 **0건** 달성
- 이미지 유실 **0%** 달성
- 멀티 인스턴스 환경에서 중복 수집 **0%** 달성

### 사용 기술
Spring Boot, ThreadPoolTaskExecutor, Resilience4j, Redis Lock, Elasticsearch, Google Sheets API

---

## 프로젝트 2: 네이버 쇼핑 최저가 대응 및 동적 가격(Dynamic Pricing) 시스템

### 📌 Situation (배경)

**비즈니스 배경**
- **비즈니스 니즈:** 매출 비중 1위 채널인 '네이버 쇼핑'의 노출 우위를 점하기 위해 가격비교 그룹 내 최저가 진입이 필수적이었으나, 수동 대응으로는 경쟁 속도를 따라갈 수 없었음
- **경쟁 환경:** 실시간으로 변동하는 경쟁사 가격에 신속하게 대응하지 못하면 노출 순위 하락 및 매출 감소 발생

**기술적 제약**
- 네이버 API의 일일 호출 한도(25,000 Call)와 엄격한 속도 제한으로 인해, 전체 상품에 대한 실시간 대응이 불가능한 딜레마 발생

### 🎯 Task (과제/목표)

**비즈니스 목표**
- API 제약 극복: 한정된 API 리소스(Quota) 내에서 매출 기여도가 높은 핵심 상품을 선별하여 최저가를 방어하는 알고리즘 구현
- 동적 가격 정책 수립: 무조건적인 최저가가 아닌, 마진율을 보장하는 범위(4% 이내) 내에서만 가격을 조정하는 안전장치 마련

**기술적 목표**
- 하이브리드 프로세스 설계: 시스템이 처리하지 못하는 예외 케이스(Missing Data)를 MD팀이 수동으로 처리할 수 있도록 **'자동+매뉴얼 하이브리드 운영 구조'** 직접 설계 및 리딩

### ⚡ Action (해결 방법)

**1. Dynamic Pricing 로직 구현**

**모델번호 기반 가격 비교 시스템**
- **의사결정 배경:** 단순한 상품명 비교가 아닌 모델번호 매핑을 통해 정확한 경쟁사 제품 매칭
- **구현 내용:**
  - 모델번호 정규화 로직 구현 (공백, 특수문자 제거)
  - [자사 판매가 vs 최저가 차이 < 4%] & [최소 마진 확보] 조건을 만족할 때만 할인율을 자동 적용
  - 마진율 계산 로직에 원가, 할인율, 프로모션 등 복합 요소 반영

**2. API Quota 효율화**

**우선순위 기반 스케줄링**
- **의사결정 배경:** 일 25,000건의 호출 한도 내에서 최대 성과를 내기 위해 데이터 기반 우선순위 설정
- **구현 내용:**
  - 매출 상위 상품, 노출 빈도 높은 상품, 최근 가격 변동이 큰 상품을 우선순위로 설정
  - 우선순위 점수 = (매출 가중치 × 0.5) + (노출 가중치 × 0.3) + (가격 변동 가중치 × 0.2)
  - 일일 25,000건 한도를 초과하지 않도록 스케줄링

**3. 협업 프로세스 주도**

**자동+매뉴얼 하이브리드 운영 구조 설계**
- **의사결정 배경:** 100% 자동화는 현실적으로 어려우므로, 시스템이 처리 가능한 영역과 사람이 판단해야 할 영역을 명확히 구분
- **구현 내용:**
  - 마케팅/MD팀과 협의하여 '가격 추종 범위(4%)' 및 '예외 상품군' 정책 확정
  - 최저가 조회 실패나 매칭 오류 건을 별도 Admin 뷰로 제공하여, MD팀이 예외 케이스만 집중 관리할 수 있도록 업무 플로우 설계
  - Slack 알림을 통해 예외 케이스 발생 시 즉시 통지

**4. 성과 검증 환경 구축**

**GA/BigQuery 연동한 데이터 분석**
- **의사결정 배경:** 가격 정책 효과를 정량적으로 검증하기 위해 데이터 분석 환경 구축
- **구현 내용:**
  - GA4를 통해 상품별 유입 트래픽, 전환율 데이터 수집
  - BigQuery에 가격 조정 이력 로그와 GA4 데이터를 통합 적재
  - 가격 조정 전후의 트래픽 및 매출 변화를 분석하는 SQL 쿼리 작성
  - 주간 리포트 자동 생성으로 경영진에게 성과 공유

### ✅ Result (성과)

**비즈니스 임팩트**
- **매출/트래픽 각각 10% 동반 상승:** 가격 경쟁력 확보를 통해 해당 상품군의 매출과 유입 트래픽이 각각 10%씩 증가함을 데이터로 검증
- **운영 효율 혁신:** 단순 반복 업무는 시스템이 전담하고, 운영팀은 전략 상품 및 예외 케이스에만 집중하는 고효율 구조 정착
- **비즈니스 리딩:** 단순 기능 개발을 넘어 API 제약 사항을 비즈니스 규칙(우선순위)과 운영 프로세스(협업)로 풀어내는 주도적 역할 수행

**기술적 성과**
- API Quota 활용 효율 **최대화** (25,000건 한도 내에서 매출 기여도 높은 상품 집중 관리)

### 사용 기술
Spring Batch, Naver Shopping API, BigQuery, Google Analytics

---

## 프로젝트 3: 데이터 기반 프로세스 최적화 및 ChatOps 자동화

### 📌 Situation (배경)

**비즈니스 제약**
- 파트너사의 잦은 품절과 수동 발주 처리로 인해 운영팀 업무의 **40%**가 단순 반복 작업에 소모됨
- 데이터가 아닌 '감'에 의존하여 클레임 원인 파악이 불가능했음

**기술적 제약**
- 상품 이미지 변경 감지를 위해 전체 파일(수 MB)을 비교하여 AWS 비용 과다 발생

### 🎯 Task (과제/목표)

**비즈니스 목표**
- **운영팀의 개입이 전혀 없는 'Zero Ops' 환경 구축**
- 로그 데이터를 기반으로 품절 리스크를 사전에 탐지하는 모니터링 체계 마련

**기술적 목표**
- 이미지 비교 비용을 **80% 이상 절감**하면서도 정확도 유지

### ⚡ Action (해결 방법)

**1. 데이터 파이프라인 구축**

**GA4와 DB 로그 통합 분석**
- **의사결정 배경:** 행동 로그(GA4)와 주문 로그(DB)를 통합 분석하여 품절 패턴을 데이터 기반으로 파악
- **구현 내용:**
  - GA4 API를 통해 상품 페이지 조회수, 장바구니 추가율, 구매 전환율 데이터 수집
  - DB에서 주문/취소/환불 로그 추출
  - BigQuery로 두 데이터를 통합 적재하여 '상습 품절 패턴' 분석 쿼리 작성
  - **분석 로직:** 조회수 대비 구매 전환율이 급격히 떨어지는 상품 = 품절 의심 상품
- **성과:** 품절 리스크 **사전 감지** 가능

**2. 비용 최적화**

**Header 해시 비교 알고리즘**
- **의사결정 배경:** 이미지 전체를 다운로드하지 않고 HTTP Header만으로 변경 여부 판단하여 비용 절감
- **구현 내용:**
  - HTTP HEAD 요청으로 Content-Length, Last-Modified, ETag 정보만 수집 (4KB)
  - 이전 해시값과 비교하여 변경 여부 판단
  - 변경 감지 시에만 전체 이미지 다운로드
- **성과:** S3 다운로드 비용 **80% 절감**

**3. ChatOps 구현**

**Slack Event API를 활용한 업무 자동화**
- **의사결정 배경:** 운영팀이 가장 많이 사용하는 Slack에서 모든 업무를 처리할 수 있도록 ChatOps 구현
- **구현 내용:**
  - Slack Event API를 활용해 메신저 내에서 '승인/반려' 버튼 클릭만으로 업무가 종결되도록 구현
  - 버튼 클릭 시 Slack Event API를 통해 백엔드로 이벤트 전달
  - 승인 시 자동으로 발주 처리, 반려 시 사유와 함께 반려 처리
  - 모든 처리 이력을 DB에 자동 기록
- **성과:** 업무 처리 시간 **평균 5분 → 30초**로 단축

### ✅ Result (성과)

**비즈니스 임팩트**
- 전체 **품절률 20% 감소** 및 클레임 사전 차단
- 운영팀 반복 업무 **100% 제거**로 고부가가치 업무 집중 환경 마련

**기술적 성과**
- 이미지 처리 비용 **80% 절감** (전체 파일 → Header 비교)
- 품절 감지 시간 **실시간** 수준으로 단축

### 사용 기술
BigQuery, GA4, Slack Event API, AWS S3, Image Hashing, Spring Batch

---

### (주)인터파크
**Backend Developer**
**기간:** 2021.09 - 2022.01 (5개월)
**부서:** 쇼핑 개발팀
**역할:** 판매자 어드민 시스템 개발 및 유지보수

## 프로젝트: Seller 어드민 성능 개선 및 레거시 리팩토링

### 📌 Situation (배경)
- 판매자 정산/주문 조회 시 Slow Query로 인한 응답 지연(**5초 이상**)
- 레거시 비즈니스 로직의 복잡도로 인한 유지보수 어려움
- 판매자의 잦은 타임아웃 불만 접수

### ⚡ Action (해결 방법)

**쿼리 최적화**
- 실행 계획 분석을 통한 인덱스 튜닝 및 불필요한 JOIN 제거
- N+1 문제 해결을 위한 Fetch Join 적용
- 복합 인덱스 설계로 쿼리 성능 향상

**코드 리팩토링**
- 복잡한 비즈니스 로직을 Service Layer로 분리하여 가독성 향상
- DTO 패턴 도입으로 계층 간 데이터 전달 명확화

### ✅ Result (성과)
- 응답 시간 **5초 이상 → 1초 이내**로 단축
- 판매자 만족도 향상

### 사용 기술
Spring Boot, JPA, MySQL

---

### (주)한국문헌정보기술
**Backend Developer**
**기간:** 2018.06 - 2021.08 (3년 2개월)
**부서:** 솔루션 개발팀
**역할:** 공공기관 기록물 관리 솔루션 SI/SM

## 프로젝트: 자체 검색 엔진 구축 및 대용량 처리 최적화

### 📌 Situation (배경)
- 기존 상용 검색 솔루션의 높은 라이선스 비용 부담
- 대량 기록물 이미지 등록 시 단건 Insert로 인한 처리 지연
- 한글 검색 정확도 부족

### 🎯 Task (과제/목표)
- 비용 절감을 위한 자체 검색 엔진 구축 및 한글 검색 정확도 확보
- 대량 이미지 등록 속도 **70% 이상 단축**

### ⚡ Action (해결 방법)

**검색 엔진 구축**
- Elasticsearch 기반 자체 검색 엔진 개발
- Nori 한글 형태소 분석기 적용으로 검색 정확도 향상
- 동의어 사전 구축으로 검색 커버리지 확대

**성능 최적화**
- 단건 Insert를 Bulk Insert 알고리즘으로 전환하여 DB 트랜잭션 횟수 최소화
- 배치 사이즈 튜닝을 통한 최적 성능 달성
- JDBC Batch Insert로 네트워크 왕복 시간 최소화

### ✅ Result (성과)
- 데이터 등록 속도 **70% 단축**
- 라이선스 비용 절감 및 검색 커스터마이징 자유도 확보
- **2021년 사내 우수사원** 선정

### 사용 기술
Elasticsearch, Nori Analyzer, Bulk Insert, Oracle

---

## Education

**대전대학교**
- 전공: 컴퓨터공학 학사
- 기간: 2011.02 - 2018.02

---

## Certifications

**정보처리기사**
- 발급기관: 한국산업인력공단
- 취득일: 2017.05

---

## Awards

**2021년 사내 우수사원**
- 회사: (주)한국문헌정보기술
- 연도: 2021
- 사유: 대용량 처리 최적화 및 검색 엔진 구축 성과
