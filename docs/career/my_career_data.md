# 윤원희 - 이력 및 경력 데이터

> 이 파일은 이력서 및 경력기술서의 모든 내용을 통합한 데이터 소스입니다.
> 이력서 개선 요청 시 이 파일의 내용을 참고하여 수정합니다.
> 작성에 있어서 풍부한 내용으로 작성 할 수 있도록 합니다.

---

# 개인 정보

- **이름:** 윤원희
- **직무:** Backend Developer (7년 차)
- **이메일:** wony9324@naver.com
- **전화번호:** 010-3555-2320
- **GitHub:** https://github.com/younwony

---

# Professional Summary

**비즈니스 문제를 대용량 시스템과 자동화로 해결하는 백엔드 개발자**

Java/Spring 기반 7년차 백엔드 개발자입니다. 이커머스 플랫폼의 상품·가격·주문·검색 영역을 폭넓게 경험하며, 단순 기능 구현보다 **"왜 이 구조여야 하는가"**를 먼저 고민합니다. 현재는 인플루언서 마케팅 솔루션 'Seeding' 프로젝트를 리딩하며, 200만 인플루언서 데이터 플랫폼을 구축하여 새로운 비즈니스 성장에 기여하고 있습니다. 성능·확장성·운영 리스크를 함께 고려한 설계를 지향하며, 기술적 제약을 비즈니스 관점에서 재정의하여 실질적인 성과로 연결해왔습니다.

**핵심 성과:**
- **검색 성능 10배 개선**: 200만 인플루언서 데이터 복합 조건 검색 타임아웃 → 역색인 기반 Elasticsearch 도입으로 10초+ → 1초 이내 달성
- **Zero Ops 달성**: 운영팀 인터뷰로 발굴한 컨텍스트 스위칭 병목 → Slack ChatOps 구축으로 반복 업무 40% → 0% 자동화
- **매출 10% 상승**: API Quota 제약 하 매출 기여도 기반 우선순위 스케줄링 → Dynamic Pricing으로 가격 경쟁력 확보
- **개발 생산성 90% 향상**: AI 에이전트(Claude Code) + MCP 활용으로 운영 도구 개발 및 API 문서화 자동화

---

# Core Competencies

| 역량 | 설명 |
|------|------|
| **Commerce Domain** | 커머스 핵심 도메인(상품·가격·주문) 비즈니스 로직 설계 및 운영 |
| **Data Pipeline** | 200만 건 이상 이기종 데이터 수집·정제·적재(ETL) 파이프라인 구축 |
| **Architecture & Performance** | 대용량 처리를 위한 병렬 아키텍처 설계 및 성능 최적화 |
| **Zero Ops & Automation** | ChatOps, 리포팅 자동화 등 운영 프로세스 100% 자동화 |
| **Reliability Engineering** | 서버 리소스 모니터링, Slow Query 분석 체계로 서비스 안정성 확보 |
| **Quality & Testing** | TDD 기반 개발, 코드 리뷰 문화 정착으로 코드 품질 향상 |
| **Cross-functional Leadership** | 요구사항 분석부터 유관 부서 협업까지 프로젝트 전 과정 리딩 |
| **AI-Assisted Development** | Claude Code 활용으로 운영 업무 자동화 및 개발 생산성 향상 |

---
# Technical Skills

### Languages/Frameworks
- Java
- Spring Boot
- Spring Batch
- JPA/Hibernate

### Database & Cache
- MySQL
- Elasticsearch
- Redis (Distributed Lock)
- Oracle

### Infra & DevOps
- AWS (EC2, S3, RDS)
- Elastic APM
- Jenkins

### Data & Analytics
- BigQuery
- GA4

### Tools & Integration
- Slack API (ChatOps)
- Google Sheets API
- Naver Shopping API
- IntelliJ
- JIRA
- Confluence

### AI Coding Assistant
- Claude Code (AI 기반 코딩 어시스턴트 활용)
- MCP (Model Context Protocol) - Confluence/Jira 연동 자동화

---

## Work Experience

### (주)구하다

**기간:** 2022.02 - 재직 중 <!-- 자동계산: 시작일 기준 현재까지 -->

**부서:** Tech 팀

**역할:** 백엔드 개발자 (Senior Backend Developer)

**담당 서비스:**
- **명품 커머스 '구하다'**: 상품·가격·주문 도메인 백엔드 개발 및 운영
- **인플루언서 마케팅 솔루션 'Seeding'**: 신규 비즈니스 프로젝트 리딩 (데이터 플랫폼 구축)

#### 프로젝트 1: [Seeding] 인플루언서 데이터 플랫폼 고도화 (200만 데이터 규모)

**📌 Situation (배경 및 문제점):**
- **수작업 의존**: 마케팅팀이 틱톡/인스타그램을 직접 탐색 후 엑셀에 수기 입력하여 관리, 인적 리소스 한계 및 데이터 최신성 유지 불가
- **캠페인 확장 한계**: 일 수집량이 수십 명 수준에 불과해 대형 캠페인 진행 및 다양한 인플루언서 매칭 불가
- **데이터 파편화**: TikTok, Instagram 등 각 플랫폼별로 팔로워, 좋아요, 이메일 등 지표가 분산되어 있어 인플루언서 성과를 통합 비교할 기준이 없음
- **검색 성능 한계**: 초기 수십만 건 규모의 단순 조회는 RDB 성능만으로 충분했으나, 수집 프로세스를 통해 200만 건 이상으로 확대되고 인플루언서의 팔로워/팔로잉 수, 콘텐츠별 조회수/좋아요 등 다양한 지표 조회와 캠페인 진행에 따른 연관 데이터 복합 조건 검색이 추가되면서 인플루언서 선정 시스템에 심각한 부하 발생 (평균 응답 시간 10초 이상)
- **이미지 데이터 유실**: CDN 링크 만료로 인한 인플루언서 프로필 이미지 유실 다수 발생, 데이터 정합성 문제

**🎯 Task (과제/목표):**
- 수집 프로세스 100% 자동화 및 다양한 API 솔루션 조합 설계 구현 (TikTok API로 팔로워/좋아요 등 메인 데이터 수집, Ensemble API/EchoTik API로 이메일·US 거주지 등 세부 데이터 수집하는 파이프라인 설계)
- 이미지 데이터 정합성 99% 이상 확보 (CDN 링크 만료 문제 해결)
- 200만 건 규모 실시간 검색 및 다양한 분석 기능 제공 (평균 팔로워 수, 표준편차 기반 상위 인플루언서 필터링, 복합 조건 검색 등)
- Seeding 캠페인 크리에이터 연결 후 컨텐츠 성과를 일별/실시간으로 Google Sheets API 기반 리포팅 자동화, 마케팅팀 별도 요청 없이 실시간 성과 확인 가능

**⚡ Action (해결 방법):**
- **요구사항 분석 및 협업**: PM과 함께 마케팅팀 정기 미팅 진행하여 Pain Point 파악, 수집 조건 우선순위 공동 정의. 기술적 제약사항을 비기술 부서가 이해할 수 있도록 설명하고 현실적인 로드맵 합의. Tech 관점에서 더 나은 방향 제시
- **멀티소스 데이터 파이프라인 설계**: TikTok API, Ensemble API, EchoTik API 및 Web Scraper를 조합한 수집 아키텍처 설계. 병렬 처리 구조로 일 평균 5,000명 이상 자동 수집 달성
- **시스템 안정성 확보**: Retry 로직으로 API 차단 방지 및 자동 복구 처리. Redis Distributed Lock 도입으로 멀티 인스턴스 환경에서 중복 수집 방지 및 API Rate Limit 준수
- **Elasticsearch 선택**: 초기 수십만 건 단순 조회는 RDB로 충분했으나, 200만 건 확대 및 인플루언서의 팔로워/팔로잉 수, 콘텐츠별 조회수/좋아요 등 다양한 지표와 캠페인 연관 데이터 복합 필터 추가로 응답 지연 심화. 구하다 커머스에서 이미 ES 운영 중이어서 동일 기술 스택 채택, 역색인 기반으로 1초 이내 달성
- **운영 자동화**: Google Sheets API 기반 리포팅 완전 자동화, 마케팅팀 실시간 성과 확인 환경 구축
- **데이터 정합성 확보**: CDN 링크 만료 문제 해결을 위한 이미지 저장 파이프라인 구축, 이미지 유실률 99% 이상 개선

**✅ Result (성과):**
- **수집 자동화**: 수작업 → 일 평균 5,000명 이상 자동 수집 (100% 자동화)
- **데이터 풀 20배 확대**: 10만 명 → 200만 명
- **검색 성능 90% 이상 개선**: 평균 응답 시간 10초+ → 1초 이내
- **Zero Ops 달성**: 리포팅 수작업 완전 제거
- **데이터 정합성 확보**: 이미지 유실률 99% 이상 개선

**💡 Impact (비즈니스 효과):**
- 대형 캠페인 진행 가능한 마케팅 커버리지 확보
- 마케팅팀 리포팅 업무 제거로 고부가가치 업무 집중 가능
- 정기 소통 체계 구축으로 요구사항 반영 속도 향상

**🔧 Tech Decision:**
> "Elasticsearch 선택 - 초기 수십만 건 단순 조회는 RDB로 충분했으나, 200만 건 확대 및 인플루언서의 팔로워/팔로잉 수, 콘텐츠별 조회수/좋아요 등 다양한 지표와 캠페인 연관 데이터 복합 필터 추가로 응답 지연 심화. 구하다 커머스에서 이미 ES 운영 중이어서 동일 기술 스택 채택, 역색인 기반으로 1초 이내 달성"
> "Redis Distributed Lock 도입 - 멀티 인스턴스 환경에서 중복 수집 방지 및 API Rate Limit 준수"

**사용 기술:**
- Spring Boot, Redis Lock, Elasticsearch, Google Sheets API

---

#### 프로젝트 2: 네이버 쇼핑 Dynamic Pricing 시스템

**📌 Situation (배경 및 문제점):**
- **비즈니스 니즈**: 매출 비중 1위 채널 '네이버 쇼핑'에서 최저가 진입이 필수적이나, 수동 대응으로는 경쟁 속도 미달
- **기술적 제약**: 네이버 API 일일 호출 한도(25,000건) 및 속도 제한으로 전체 상품 실시간 대응 불가

**🎯 Task (과제/목표):**
- API 제약 내 매출 기여도 높은 핵심 상품 선별 및 최저가 방어 알고리즘 구현
- 마진율 4% 보장 범위 내 가격 조정 안전장치 마련
- 자동 + 수동 하이브리드 운영 구조 설계

**⚡ Action (해결 방법):**
- **비즈니스 규칙 설계 리딩**: 마케팅/MD팀과 협의하여 가격 추종 범위(4%), 최소 마진 기준, 예외 상품군 정의. API Quota 제약을 비즈니스 우선순위로 해결하는 방안 제안 및 합의 도출
- **Dynamic Pricing 엔진 개발**: 모델번호 매핑 기반 경쟁사 최저가 수집 후, [자사가 vs 최저가 차이 < 4%] & [최소 마진 확보] 조건 충족 시 할인율 자동 적용
- **API Quota 최적화**: 매출 기여도/노출 중요도 기반 상품 우선순위 스케줄링. Spring Batch로 배치 작업 안정성 확보
- **하이브리드 운영 구조 설계**: 자동 처리 + MD팀 수동 처리 통합. 예외 케이스 Admin 뷰 제공으로 집중 관리 가능한 업무 플로우 확립
- **성과 검증 환경 구축**: 가격 조정 이력 로그화, GA/BigQuery 연동으로 정량 분석 환경 구축

**✅ Result (성과):**
- **매출/트래픽 10% 동반 상승**: 가격 경쟁력 확보로 해당 상품군 매출·트래픽 각각 10% 증가 (데이터 검증 완료)
- **운영 효율 혁신**: 단순 반복 업무 시스템 전담, MD팀은 전략 상품·예외 케이스에만 집중

**💡 Impact (비즈니스 효과):**
- 가격 경쟁력 확보로 네이버 쇼핑 노출 우위 달성
- MD팀 고효율 구조 정착: 전략적 의사결정에 집중
- 정기 협의 체계 구축으로 가격 정책 신속 대응

**🔧 Tech Decision:**
> "Spring Batch 선택 - 대량 상품 가격 조정의 트랜잭션 안정성 및 Chunk 기반 처리로 메모리 효율화"
> "우선순위 스케줄링 - API Quota 25,000건 제약 하 매출 기여도 상위 상품 집중으로 ROI 극대화"

**사용 기술:**
- Spring Batch, Naver Shopping API, BigQuery, Google Analytics

---

#### 프로젝트 3: 메인 페이지 큐레이션 시스템 구축

**📌 Situation (배경 및 문제점):**
- **정적 메인 화면 구조**: 메인 페이지가 하드코딩되어 상품 노출이 기획전 단위로만 가능, 마케팅 대응 유연성 부족
- **MD팀 자율성 제한**: 상품 구성 변경 시 개발자 개입 필수, 실시간 마케팅 대응 불가
- **UI 다양성 부족**: 단일 형태의 상품 리스트만 제공, 고객 경험 및 시각적 차별화 한계
- **확장성 문제**: 새로운 전시 타입 추가 시 대규모 코드 수정 필요

**🎯 Task (과제/목표):**
- MD팀이 개발자 개입 없이 실시간으로 메인 페이지 상품 구성 변경 가능한 시스템 구축
- 다양한 아이템 타입(상품/배너/리뷰/캐러셀 등)과 뷰 타입(그리드/스와이프 등) 조합으로 유연한 UI 지원
- 홈/카테고리/기획전/타임딜/브랜드/장바구니 등 전시 위치 통합 관리 체계 구축
- 향후 기능 확장 용이한 Enum 기반 타입 시스템 설계

**⚡ Action (해결 방법):**
- **요구사항 분석**: MD팀과 협업하여 상품 전시 Pain Point 파악. 기획전 의존도 높은 현 구조의 한계점 분석
- **유연한 타입 시스템 설계**: Enum 기반으로 전시 위치, 아이템 타입, 뷰 타입, 큐레이션 타입 정의. 신규 타입 추가 시 Enum 값만 추가하면 확장 가능한 구조
- **위치별 큐레이션 시스템 구현**: 홈/카테고리/기획전/타임딜/브랜드/장바구니/팝업 등 위치별 독립 관리. 전시 순서, 노출 기간, 플랫폼별 설정 지원
- **알고리즘 기반 자동 큐레이션**: BEST, NEW, SELLER_BEST, CART_RECOMMEND 등 자동 큐레이션 타입 구현. 수동 + 자동 하이브리드 구조
- **다양한 뷰 타입 지원**: 세로 스크롤, 가로 스와이프, 그리드형, 아이콘형 등 다양한 레이아웃 제공
- **멀티 플랫폼 스키마 통합**: Web, iOS, AOS 딥링크 스키마 통합 설계로 플랫폼별 분기 로직 제거
- **캐시 최적화**: 인메모리 캐시(3분 TTL) 적용으로 외부 의존성 없이 API 응답 속도 최적화

**✅ Result (성과):**
- **MD팀 자율 운영 달성**: 개발자 개입 없이 실시간 메인 페이지 구성 변경 가능
- **UI 다양성 확보**: 아이템 타입 × 뷰 타입 조합으로 다양한 레이아웃 구성 가능
- **확장성 검증**: Enum 기반 설계로 신규 전시 위치/타입 추가 시 Enum 값만 추가하여 빠른 확장
- **운영 효율화**: 기획전 의존도 감소, 일상적 상품 교체를 MD팀 자체 처리

**💡 Impact (비즈니스 효과):**
- MD팀 마케팅 대응력 향상: 시즌/트렌드 변화에 실시간 대응
- 메인 페이지 컨텐츠 다양화로 고객 체류 시간 및 탐색 경험 개선
- 개발팀 반복 업무 제거로 핵심 기능 개발에 집중

**🔧 Tech Decision:**
> "Enum 기반 타입 시스템 - 전시 위치/아이템/뷰/큐레이션 타입을 Enum으로 정의하여 타입 안전성 확보 및 확장 용이성 달성. 신규 타입은 Enum 값 추가만으로 확장"
> "Strategy 패턴 적용 - 아이템 타입별 렌더링 로직 분리로 OCP 원칙 준수, 각 타입 독립적 처리"
> "인메모리 캐시 선택 - 큐레이션 데이터 크기가 작고 서버별 독립 캐시로 충분. Redis 의존성 제거로 인프라 단순화, 3분 TTL로 실시간성과 성능 균형"

**사용 기술:**
- Java, Spring Boot, MySQL, Spring Cache (In-Memory)

---

#### 프로젝트 4: 상품 이미지 정합성 확보 및 클레임 방지 시스템

**📌 Situation (배경 및 문제점):**
- 해외 부티크 상품 이미지(색상, 디테일) 변경 시 URL이 동일하게 유지되어 기존 시스템이 변경 감지 불가
- 쇼핑몰 노출 이미지와 실제 배송 상품 불일치로 '상품 상이' 클레임 다수 발생
- 반품 처리 비용 증가 및 브랜드 신뢰도 하락, CS팀 지속적 개선 요청

**🎯 Task (과제/목표):**
- 이미지 데이터 정합성 100% 확보로 고객 클레임 원천 차단
- 파일 자체 변경 감지 가능한 고성능/저비용 검증 로직 구현
- 수동 검수 프로세스의 시스템 전환으로 운영 리소스 절감

**⚡ Action (해결 방법):**
- **문제 원인 분석**: CS팀과 협업하여 클레임 패턴 분석. URL 동일하나 이미지 내용 변경되는 케이스 발견, 해시 기반 검증 방안 제안
- **해시 기반 검증 시스템 구축**: SHA256 해시값 비교로 이미지 변경 정밀 감지. 이미지 파일의 첫 0~5KB 영역(메타데이터 포함)만 확인하여 변경 여부 빠르게 판단
- **동기화 파이프라인 고도화**: 해시값 O(1) 비교로 변경 감지 시 S3 즉시 업데이트
- **운영 자동화**: 24시간 무인 이미지 동기화 운영 체계 구축

**✅ Result (성과):**
- **클레임 Zero 달성**: 이미지 불일치 오배송 클레임 완전 제거
- **반품 비용 절감**: 이미지 상이로 인한 반품 처리 비용 제거
- **Zero Ops 달성**: 수동 검수 → 자동화로 운영 리소스 절감

**💡 Impact (비즈니스 효과):**
- 고객 신뢰도 회복으로 구매 전환율 안정화
- CS팀 클레임 처리 업무 부담 제거
- 브랜드 이미지 보호

**🔧 Tech Decision:**
> "SHA256 해시 검증 - URL 동일해도 이미지 내용 변경 감지"
> "S3 직접 업로드 - CDN 캐시 무효화 없이 즉시 반영, 운영 복잡도 제거"

**사용 기술:**
- Java, Spring Boot, AWS S3, Image Hashing (SHA256)

---

#### 프로젝트 5: ChatOps 기반 운영 프로세스 자동화 (Zero Ops)

**📌 Situation (배경 및 문제점):**
- **소통 채널 파편화**: 발주·클레임 처리가 이메일, 개인 메신저, 구두 요청으로 분산, 정보 누락 및 히스토리 추적 불가
- **운영 비효율**: 반복적인 발주 확인과 수동 처리로 운영팀 업무 시간의 약 40%가 단순 작업에 소모
- **현업 불만**: "어디로 요청해야 할지 모르겠다", "처리 결과를 즉시 알고 싶다", "요청이 제대로 접수되었는지 확인이 안 된다" 등 지속 접수

**🎯 Task (과제/목표):**
- 이메일, 메신저, 구두 등 다중 채널로 분산된 운영 요청 창구를 Slack으로 일원화하여 현업 혼란 해소
- 별도 어드민 접속 없이 메신저 내 업무 완결 'Zero Ops' 환경 구축
- 업무 처리 과정 투명화

**⚡ Action (해결 방법):**
- **현업 인터뷰 직접 리딩**: 운영팀·유관 부서 인터뷰 주도, 가장 큰 병목(어드민 접속 → 데이터 확인 → 메신저 공유의 컨텍스트 스위칭) 발굴
- **사용자 중심 플랫폼 선정**: 구성원이 가장 익숙한 Slack 선택으로 진입 장벽 제거, 채택률 극대화
- **협업 워크플로우 설계**: 스레드 기능으로 논의 집중, 버튼 클릭만으로 업무 종결 가능한 구조
- **ChatOps 시스템 구축**: Slack Event API 기반 Interactive Component(버튼, 모달)로 발주 승인/반려, 클레임 처리 구현. 이벤트 발생 시 즉시 알림 + DB 처리 완료

**✅ Result (성과):**
- **Zero Ops 달성**: 운영팀 수동 업무 40% → 0% 완전 자동화
- **채널 100% 통합**: 파편화된 채널 일원화로 부서 간 협업 속도 증대
- **업무 투명성 확보**: 모든 요청·처리 내역 Slack 기록으로 히스토리 추적 가능

**💡 Impact (비즈니스 효과):**
- 운영팀 고부가가치 업무 집중 가능
- 휴먼 에러 방지로 클레임 감소
- 현업 만족도 향상: "요청 창구 명확", "처리 결과 즉시 확인"

**🔧 Tech Decision:**
> "Slack 선택 - 구성원이 가장 익숙한 플랫폼, 별도 앱 설치 없이 즉시 도입으로 채택률 극대화"
> "Event API + Interactive Component - 버튼 클릭만으로 DB 처리 완료, 컨텍스트 스위칭 제거"

**사용 기술:**
- Java, Spring Boot, Slack Event API

---

#### 프로젝트 6: 개발 문화 개선 및 시스템 안정성 강화

**📌 Situation (배경 및 문제점):**
- 팀 내 통일된 코드 컨벤션과 리뷰 프로세스 부재로 개발자마다 스타일이 상이, 협업 비용 증가 및 품질 저하 발생.
- 코드 리뷰 없이 배포되어 운영 장애 및 사이드 이펙트 반복 발생.
- 서버 리소스(디스크, 메모리) 이슈 발생 시 감지 체계 부재로 장애 사후 대응.
- Slow Query로 인한 성능 저하 발생해도 원인 파악에 시간 소요. 검색 API TPS 200 수준, 상품상세 Review API Latency 최대 4초로 사용자 경험 저하.
- 월간/일간 운영성 반복 업무에 시니어 개발자 리소스가 과다 투입되어 핵심 개발 시간 부족.
- API 문서 최신화 및 작업 내용 문서화에 개발자 리소스 과다 소요, 문서 최신화 지연으로 클라이언트 협업 비효율 발생.

**🎯 Task (과제/목표):**
- 건강한 코드 리뷰 문화와 품질 기준을 정착시켜 운영 장애 사전 차단.
- TDD 기반 개발 프로세스 도입으로 코드 품질 향상.
- 서버 리소스 모니터링 및 Slow Query 분석 체계 구축으로 성능 이슈 사전 감지.
- 핵심 API 성능 최적화: 검색 TPS 10배 이상 향상, Review API Latency 90% 개선 목표.
- 코딩 컨벤션 수립 및 AI 에이전트 활용 자동화 도입으로 운영성 개선.
- MCP(Model Context Protocol) 활용 Atlassian(Confluence/JIRA) 연동으로 API 문서 최신화 자동화.

**⚡ Action (해결 방법):**
- **코드 리뷰 문화 정착**: PR 기반 리뷰 프로세스 제안 및 도입, 배포 전 최소 2인 승인 체계 확립. 설계·성능·운영 요소를 함께 논의하는 "더 나은 설계" 중심 리뷰 문화 형성.
- **TDD 기반 개발 도입**: 신규 기능 개발 시 TDD 적용, 테스트 코드 작성 문화 정착. 핵심 비즈니스 로직에 대한 단위 테스트 커버리지 확보.
- **서버 리소스 모니터링 구축**: 디스크 사용량, 메모리 사용량 체크 스크립트 구성 → 임계치 초과 시 Slack 알림 자동 발송. 장애 발생 전 선제적 대응 가능.
- **Elastic APM 기반 Slow Query 분석 체계**: Elastic APM 활용하여 2초 이상 Slow Query 추출 및 시각화. 인덱스 누락, 불필요한 테이블 조인, 비효율적 SELECT 구문 식별 후 최적화.
- **검색 API 성능 최적화**: Elasticsearch Hit Index Count 알고리즘 분석 및 병목 지점 파악. 인덱싱 전략 재설계로 TPS 200 → 3,000 달성 (1500% 향상).
- **상품상세 Review API 개선**: 객체화 구조 채용으로 유지보수성 향상. Slow Query 분석 후 인덱스 최적화로 Latency 100~4,000ms → 30~80ms 개선 (90% 단축).
- **코딩 컨벤션 수립**: Java/Spring 코딩 컨벤션을 팀원들과 함께 정의하고 문서화. 신규 입사자 온보딩 시 즉시 적용 가능하도록 체계화.
- **AI 에이전트 활용 자동화**: Claude Code를 활용하여 반복적인 운영성 도구 개발에 AI 페어프로그래밍 적용. 개발 시간 90% 단축 (10시간 → 1시간).
- **API 문서 최신화 자동화**: Atlassian MCP(Model Context Protocol) 활용, JIRA 티켓 작업 완료 후 해당 작업 Git Branch에서 MCP를 통해 Confluence에 API 문서 자동 생성. 작업 컨텍스트 유지한 채 문서화하여 정보 손실 방지. 표준 API 문서 템플릿 정의로 클라이언트와의 커뮤니케이션 비용 절감.

**✅ Result (성과):**
- **코드 품질 개선**: TDD 도입으로 배포 후 버그·핫픽스 건수 감소, 운영 장애 사전 차단
- **검색 API TPS 1500% 향상**: 200 → 3,000 TPS 달성으로 트래픽 대응력 확보
- **Review API Latency 90% 개선**: 4,000ms → 80ms로 사용자 응답 속도 대폭 개선
- **Slow Query 최적화**: 2초 이상 Slow Query 식별 및 인덱싱 적용으로 쿼리 성능 개선
- **서버 안정성 확보**: 디스크/메모리 알림으로 리소스 이슈 사전 감지, 장애 예방
- **온보딩 속도 단축**: 일관된 컨벤션과 리뷰 프로세스로 신규 입사자 생산 투입 시점 앞당김
- **운영 업무 90% 단축**: 운영성 도구 개발 시간 10시간 → 1시간으로 개선 (AI 에이전트 활용)
- **API 문서화 업무 90% 자동화**: MCP 활용으로 개발자 문서 작성 부담 경감

**💡 Impact (비즈니스 효과):**
- 리소스 모니터링으로 장애 사전 감지, 서비스 가용성 향상
- Slow Query 최적화로 사용자 응답 속도 개선, UX 향상
- TDD/코드 리뷰로 코드 품질 향상, 유지보수 비용 절감
- 시니어 개발자가 반복 작업에서 해방되어 핵심 도메인 개발·아키텍처 작업에 집중
- 개발자 생산성 향상 및 팀 역량 강화
- API 문서 최신화 자동화로 클라이언트 협업 효율 증대

**🔧 Tech Decision:**
> "Elasticsearch Hit Index Count 최적화 - 기존 전체 문서 조회 방식에서 인덱싱 전략 재설계로 TPS 1500% 향상 달성"
> "Elastic APM 활용 - 기존 인프라 활용으로 추가 비용 없이 Slow Query 시각화 및 분석 체계 구축"
> "Slack 알림 시스템 - 팀이 이미 사용 중인 플랫폼으로 별도 도구 없이 즉시 이슈 인지 가능"
> "AI Agent(Claude Code) + MCP 도입 - 자연어 명령으로 운영 도구 개발 90% 시간 단축, Atlassian 연동으로 문서화 자동화"

**사용 기술:**
- Java, Spring Boot, Elasticsearch, Elastic APM, TDD (JUnit, Mockito), Slack API, Shell Script, Claude Code (AI Agent), MCP (Atlassian)

---


### (주)인터파크

**기간:** 2021.09 - 2022.01 (5개월)

**부서:** 쇼핑 개발팀

**역할:** 백엔드 개발자 (Seller Admin 시스템)

#### 프로젝트: 레거시 시스템 TDD 도입 및 테스트 문화 정착

**📌 Situation (배경 및 문제점):**
- 레거시 시스템에 테스트 코드가 전무하여 기능 변경 시 사이드 이펙트 파악 불가
- 판매자 정산/주문 조회 등 핵심 기능의 정합성 검증 수단 부재
- 코드 수정 시 수동 테스트에 의존하여 배포 리스크 증가 및 개발 속도 저하

**🎯 Task (과제/목표):**
- 핵심 비즈니스 기능에 대한 테스트 코드 작성으로 변경 안정성 확보
- 신규 기능 개발 시 TDD 적용으로 코드 품질 향상
- 레거시 코드 리팩토링 시 회귀 테스트 기반 마련

**⚡ Action (해결 방법):**
- **TDD 도입**: 신규 기능 개발부터 TDD 방식 적용, 테스트 우선 개발 문화 정착
- **핵심 기능 테스트 추가**: Seller 아이템 조회, 특정 셀러의 주문 관련 통합 데이터 조회 등 핵심 비즈니스 로직에 단위 테스트 작성
- **코드 리팩토링**: 테스트 가능한 구조로 복잡한 비즈니스 로직을 Service Layer로 분리
- **팀 내 테스트 문화 전파**: 테스트 작성 가이드 공유 및 코드 리뷰 시 테스트 코드 포함 여부 검토

**✅ Result (성과):**
- **테스트 커버리지 확보**: 핵심 비즈니스 로직에 대한 단위 테스트 구축으로 변경 안정성 확보
- **배포 안정성 향상**: 테스트 기반 회귀 검증으로 배포 리스크 감소
- **코드 가독성 향상**: 테스트 가능한 구조로 리팩토링하여 유지보수 효율 개선
- **테스트 문화 정착**: 팀 내 TDD 기반 개발 방식 정착

**💡 Impact (비즈니스 효과):**
- 테스트 기반 개발 문화 정착으로 코드 변경에 대한 신뢰성 확보
- 수동 테스트 시간 절감으로 개발 생산성 향상

**사용 기술:**
- Java, Spring Framework, Oracle, JUnit, Mockito

---

### (주)한국문헌정보기술

**기간:** 2018.06 - 2021.08 (3년 2개월)

**부서:** 솔루션 개발팀

**역할:** 백엔드 개발자 (공공기관 기록물 관리 솔루션)

#### 프로젝트: 자체 검색 엔진 구축 및 대용량 처리 최적화

**📌 Situation (배경 및 문제점):**
- 솔루션 납품에 필요한 상용 검색엔진 라이선스 비용이 수천만원에 달하여 전체 프로젝트 비용 상승
- 솔루션 납품 이후 초기 데이터 구축 시 대량 기록물 이미지 등록에 단건 Insert 방식으로 처리 시간 최소 10시간 이상 소요

**🎯 Task (과제/목표):**
- 비용 절감을 위한 자체 검색 엔진 구축 및 한글 검색 정확도 확보
- PDF, DOCX 등 다양한 문서 데이터의 색인 구성 (Apache Tika 플러그인 활용)
- 대량 이미지 등록 속도 70% 이상 단축

**⚡ Action (해결 방법):**
- **검색 엔진 구축**: Elasticsearch 기반 자체 검색 엔진 개발, Nori 한글 형태소 분석기 적용으로 검색 정확도 향상. Apache Tika 플러그인 활용하여 PDF, DOCX 등 다양한 문서 형식 색인 지원
- **DB 성능 최적화**: 단건 Insert → Bulk Insert 전환으로 DB 트랜잭션 횟수 최소화
- **이미지 처리 병렬화**: 이미지 1개당 다양한 유형의 썸네일(2000px, 1000px, 700px, 500px, 300px) 구성 필요. 최초 원본 이미지에서 가장 큰 해상도(2000px) 썸네일 생성 후, 해당 이미지를 기반으로 나머지 해상도 썸네일을 병렬 처리하여 리소스 절감 및 속도 향상
- **비동기 처리 도입**: 이미지 등록 프로세스에 비동기 처리 적용으로 전체 처리 속도 개선

**✅ Result (성과):**
- **데이터 등록 속도 70% 단축**: 10시간 이상 → 3시간 이내
- 라이선스 비용 수천만원 절감 및 검색 커스터마이징 자유도 확보
- **2021년 사내 우수사원** 선정

**💡 Impact (비즈니스 효과):**
- 외부 라이선스 의존성 제거로 프로젝트 수익성 향상
- 한글 검색 정확도 향상으로 공공기관 사용자 만족도 개선
- 병렬/비동기 처리 도입으로 초기 데이터 구축 기간 단축

**사용 기술:**
- Java, Spring Framework, Elasticsearch, Nori Analyzer, Apache Tika, Oracle

---

## Education

**대전대학교**
- 전공: 컴퓨터공학 학사
- 기간: 2011.02 - 2018.02

---

## Certifications

**정보처리기사**
- 발급기관: 한국산업인력공단
- 취득일: 2017.05

---

## Awards

**2021년 사내 우수사원**
- 회사: (주)한국문헌정보기술
- 연도: 2021
- 사유: 대용량 처리 최적화 및 검색 엔진 구축 성과

---

## 업데이트 가이드

이 파일에 새로운 경력이나 프로젝트를 추가할 때는 다음 형식을 따라주세요:

### 프로젝트 추가 시 형식 (STAR 기법)

```markdown
#### 프로젝트: [프로젝트명]

**📌 Situation (배경):**
- 당시 상황 및 문제점 설명

**🎯 Task (과제/목표):**
- 해결해야 할 목표 (구체적 수치 포함)

**⚡ Action (해결 방법):**
- 본인이 수행한 핵심 역할
- 기술적 의사결정 및 적용 기술

**✅ Result (성과):**
- 정량적 수치로 표현된 성과

**사용 기술:**
- 기술스택 나열
```

### 회사 경력 추가 시 형식

```markdown
### [회사명]
**기간:** YYYY.MM - YYYY.MM (N년 N개월)
**부서:** 부서명
**역할:** 담당 역할
```
