# 윤원희 - 경력기술서

**Backend Developer | 7년차**

---

## 인적 사항

- **이름:** 윤원희
- **이메일:** wony9324@naver.com
- **연락처:** 010-3555-2320
- **GitHub:** https://github.com/younwony

---

## Professional Summary

**비즈니스 문제를 대용량 시스템과 자동화로 해결하는 백엔드 개발자**

Java/Spring 기반 7년차 백엔드 개발자입니다. 이커머스 플랫폼의 상품·가격·주문·검색 영역을 폭넓게 경험하며, 단순 기능 구현보다 **"왜 이 구조여야 하는가"**를 먼저 고민합니다. 성능·확장성·운영 리스크를 함께 고려한 설계를 지향하며, 기술적 제약을 비즈니스 관점에서 재정의하여 실질적인 성과로 연결해왔습니다.

**핵심 성과:**
- **검색 성능 100배 개선**: RDB 복합 조건 검색 타임아웃 문제 → 역색인 기반 Elasticsearch 도입으로 10초 → 0.1초 달성 (200만 건)
- **Zero Ops 달성**: 운영팀 인터뷰로 발굴한 컨텍스트 스위칭 병목 → Slack ChatOps 구축으로 반복 업무 40% → 0% 자동화
- **매출 10% 상승**: API Quota 제약 하 매출 기여도 기반 우선순위 스케줄링 → Dynamic Pricing으로 가격 경쟁력 확보
- **개발 생산성 90% 향상**: AI 에이전트(Claude Code) + MCP 활용으로 운영 도구 개발 및 API 문서화 자동화

---

## Core Competencies

| 역량 | 설명 |
|------|------|
| **Commerce Domain** | 커머스 핵심 도메인(상품·가격·주문) 비즈니스 로직 설계 및 운영 |
| **Data Pipeline** | 200만 건 이상 이기종 데이터 수집·정제·적재(ETL) 파이프라인 구축 |
| **Architecture & Performance** | 대용량 처리를 위한 병렬 아키텍처 설계 및 성능 최적화 |
| **Zero Ops & Automation** | ChatOps, 리포팅 자동화 등 운영 프로세스 100% 자동화 |
| **Reliability Engineering** | 서버 리소스 모니터링, Slow Query 분석 체계로 서비스 안정성 확보 |
| **Quality & Testing** | TDD 기반 개발, 코드 리뷰 문화 정착으로 코드 품질 향상 |
| **Cross-functional Leadership** | 요구사항 분석부터 유관 부서 협업까지 프로젝트 전 과정 리딩 |
| **AI-Assisted Development** | Claude Code + MCP 활용으로 운영 업무 자동화 및 개발 생산성 향상 |

---

## Technical Skills

**Languages & Frameworks**: Java, Spring Boot, Spring Batch, JPA/Hibernate

**Database & Cache**: MySQL, Elasticsearch, Redis (Distributed Lock), Oracle

**Infra & DevOps**: AWS (EC2, S3, RDS), Elastic APM, Jenkins

**Tools & Integration**: Slack API, Google Sheets API, Naver Shopping API, BigQuery, GA4

**AI & Automation**: Claude Code, MCP (Atlassian, Confluence), API Documentation Automation

---

## Work Experience

### (주)구하다
**Backend Developer (Senior)** | 2022.02 - 현재 (3년 11개월)

---

### 인플루언서 데이터 플랫폼 고도화 (2022.02 - 현재)

**역할**: 백엔드 아키텍처 설계 주도 (1인 개발)

**Tech Stack**: Spring Boot, Elasticsearch, Redis Lock, Google Sheets API

**[프로젝트 배경]**
마케팅팀이 틱톡/인스타그램을 직접 탐색하고 엑셀에 수기 입력하여 인플루언서를 관리하고 있었습니다. 하루 수집 가능한 인플루언서가 수십 명 수준에 불과해 대형 캠페인 진행이 불가능했습니다. TikTok, Instagram 등 각 플랫폼별로 팔로워, 좋아요, 이메일 등 지표가 분산되어 있어 인플루언서 성과를 통합 비교할 기준이 없었습니다. 초기 수십만 건 규모의 단순 조회는 RDB 성능만으로 충분했으나, 수집 프로세스를 통해 200만 건 이상으로 확대되고 인플루언서의 팔로워/팔로잉 수, 콘텐츠별 조회수/좋아요 등 다양한 지표 조회와 캠페인 진행에 따른 연관 데이터 복합 조건 검색이 추가되면서 검색 시스템에 심각한 부하가 발생했습니다(평균 응답 시간 10초 이상). CDN 링크 만료로 인한 프로필 이미지 유실도 다수 발생했습니다.

**[주요 성과]**
- **검색 성능 100배 향상 (10초 → 0.1초)**: Elasticsearch 역색인 기반 검색 엔진을 구축하여 200만 건 복합 조건 검색 시 RDB 타임아웃 문제 해결. 동적 필터 100가지 조합을 커버하기 위해 RDB 복합 인덱스 대신 역색인 방식 선택.
- **데이터 수집 자동화로 마케팅 커버리지 20배 확대 (10만 → 200만)**: TikTok API로 팔로워/좋아요 등 메인 데이터 수집, Ensemble/EchoTik API로 이메일·US 거주지 등 세부 데이터 수집하는 파이프라인 설계. Redis 분산 락으로 멀티 인스턴스 환경에서 중복 수집 방지.
- **리포팅 업무 Zero Ops 달성**: Google Sheets API 연동으로 마케팅팀 주간 리포트 작성 업무를 완전 자동화. 별도 요청 없이 실시간으로 캠페인 성과 확인 가능.
- **데이터 정합성 99% 확보**: CDN 링크 만료로 인한 이미지 유실 문제를 이미지 저장 파이프라인 구축으로 해결.

**[기술적 의사결정]**
- PM과 마케팅팀 정기 미팅 진행하여 Pain Point 파악, 수집 조건 우선순위 공동 정의
- Elasticsearch 선택: 초기 수십만 건 단순 조회는 RDB로 충분했으나, 200만 건 확대 및 인플루언서의 팔로워/팔로잉 수, 콘텐츠별 조회수/좋아요 등 다양한 지표와 캠페인 연관 데이터 복합 필터 추가로 응답 지연 심화. 구하다 커머스에서 이미 ES 운영 중이어서 동일 기술 스택 채택, 역색인 기반으로 1초 이내 달성
- Redis Distributed Lock 도입: 멀티 인스턴스 환경에서 중복 수집 방지 및 API Rate Limit 준수

---

### 네이버 쇼핑 Dynamic Pricing 시스템 (2023.01 - 2023.06)

**역할**: 가격 정책 로직 설계 주도 (기획/운영팀 협업)

**Tech Stack**: Spring Batch, Naver Shopping API, BigQuery, GA4

**[프로젝트 배경]**
매출 비중 1위 채널인 네이버 쇼핑의 노출 우위를 점하기 위해 가격비교 그룹 내 최저가 진입이 필수였습니다. 그러나 네이버 API의 일일 호출 한도(25,000건)와 엄격한 속도 제한으로 전체 상품 실시간 대응이 불가능했습니다.

**[주요 성과]**
- **대상 상품 매출 10% 상승**: 매출 기여도 상위 20% 상품 집중 모니터링 전략과 마진 4% 보장 룰 엔진을 설계하여 가격 경쟁력 확보. GA/BigQuery 연동으로 가격 정책 적용 전후 트래픽·매출 변화를 정량 분석.
- **API 호출량 80% 절감 (25,000건 → 5,000건/일)**: 우선순위 기반 스케줄링으로 API 제약 내 핵심 상품 최저가 대응률 90% 달성. 기술적 제약을 비즈니스 우선순위로 해결하는 방안을 직접 제안.
- **MD팀 가격 조정 업무 80% 감소**: 자동 가격 조정 시스템 도입으로 일 2시간 소요되던 수동 업무를 예외 케이스만 처리하도록 전환. 최저가 조회 실패/매칭 오류 건을 Admin 뷰로 제공.

**[기술적 의사결정]**
- Spring Batch 선택: 대량 상품 가격 조정의 트랜잭션 안정성 및 Chunk 기반 처리로 메모리 효율화
- 하이브리드 운영 구조: 시스템 자동 처리 + MD팀 수동 처리를 통합한 운영 구조 직접 설계

---

### 메인 페이지 큐레이션 시스템 구축 (2023.01 - 2023.02)

**역할**: 큐레이션 시스템 설계 및 구현 주도

**Tech Stack**: Spring Boot, MySQL, Spring Cache (In-Memory)

**[프로젝트 배경]**
메인 페이지가 하드코딩되어 상품 노출이 기획전 단위로만 가능했습니다. MD팀이 상품 구성을 변경하려면 개발자 개입이 필수였고, 실시간 마케팅 대응이 불가능했습니다. 단일 형태의 상품 리스트만 제공되어 고객 경험 및 시각적 차별화에 한계가 있었습니다.

**[주요 성과]**
- **MD팀 실시간 자율 운영 달성**: 개발자 개입 없이 메인 페이지 상품 구성을 실시간으로 변경 가능한 어드민 시스템 구축. 기획전 의존도 감소로 일상적 상품 교체를 MD팀 자체 처리.
- **63가지+ UI 레이아웃 조합 제공**: 9가지 아이템 타입(상품/배너/리뷰/캐러셀/칩 등) × 7가지 뷰 타입(그리드/스와이프 등) 조합으로 다양한 시각적 표현 지원.
- **14개 전시 위치 통합 관리**: 홈/카테고리(여성/남성/키즈)/기획전/타임딜/브랜드/장바구니/팝업 등 14개 위치를 하나의 시스템으로 통합 관리.
- **확장성 검증**: Enum 기반 설계로 신규 전시 위치/타입 추가 시 Enum 값만 추가하여 빠른 확장 가능.

**[기술적 의사결정]**
- Enum 기반 타입 시스템: 전시 위치(14종), 아이템 타입(9종), 뷰 타입(7종), 큐레이션 타입(8종)을 Enum으로 정의하여 타입 안전성 확보 및 확장 용이성 달성
- Strategy 패턴 적용: 아이템 타입별 렌더링 로직 분리로 OCP 원칙 준수, 9가지 타입 각각 독립적 처리
- 인메모리 캐시 선택: 큐레이션 데이터 크기가 작고 서버별 독립 캐시로 충분. Redis 의존성 제거로 인프라 단순화, 3분 TTL로 실시간성과 성능 균형

---

### 상품 이미지 정합성 확보 시스템 (2023.07 - 2023.09)

**역할**: 해시 기반 검증 시스템 설계 및 구현 (1인 개발)

**Tech Stack**: Spring Boot, AWS S3, Image Hashing (SHA256)

**[프로젝트 배경]**
해외 부티크의 상품 이미지(색상, 디테일)가 변경되었음에도 URL이 동일하게 유지되어, 기존 시스템이 변경 사항을 감지하지 못했습니다. 쇼핑몰 노출 이미지와 실제 배송 상품이 다른 '상품 상이' 클레임이 월 20건 이상 발생하고 있었습니다.

**[주요 성과]**
- **이미지 불일치 클레임 Zero 달성 (월 20건+ → 0건)**: SHA256 해시 검증 시스템을 구축하여 URL 동일 이미지 변경을 100% 감지. 고객 신뢰도 회복으로 구매 전환율 안정화.
- **변경 감지 최적화**: 이미지 파일의 첫 0~5KB 영역(메타데이터 포함)만 확인하여 변경 여부 빠르게 판단.
- **검수 업무 Zero Ops 달성**: 수동 샘플링 방식에서 전수 자동화로 전환하여 CS팀 클레임 처리 부담 제거. 24시간 이미지 동기화 운영.

**[기술적 의사결정]**
- SHA256 해시 검증: URL 동일해도 이미지 내용 변경 감지
- S3 직접 업로드: CDN 캐시 무효화 없이 즉시 반영되는 구조로 운영 복잡도 제거

---

### ChatOps 기반 운영 프로세스 자동화 (2024.01 - 2024.03)

**역할**: 현업 인터뷰 직접 리딩 및 ChatOps 설계

**Tech Stack**: Spring Boot, Slack Event API, Interactive Components

**[프로젝트 배경]**
발주·클레임 처리가 이메일, 개인 메신저, 구두 요청 등으로 분산되어 정보 누락 및 히스토리 추적이 불가능했습니다. 운영팀 전체 업무 시간의 약 40%가 반복적인 발주 확인과 수동 처리에 소모되고 있었습니다. 현업에서는 "어디로 요청해야 할지 모르겠다", "처리 결과를 즉시 알고 싶다" 등의 불만이 지속 접수되었습니다.

**[주요 성과]**
- **운영팀 수동 업무 Zero Ops 달성 (40% → 0%)**: Slack 기반 ChatOps와 Interactive Component를 도입하여 버튼 클릭만으로 DB 처리 완료. 별도 어드민 접속 없이 메신저 내에서 업무 완결.
- **운영 요청 채널 100% 통합**: 이메일/메신저/구두로 분산된 5개 채널을 Slack으로 단일화하여 정보 누락 및 히스토리 추적 문제 해결. 모든 요청·처리 내역이 채널에 기록.
- **ChatOps 패턴 타 팀 확산**: 마케팅팀, CS팀 요청 처리로 동일 패턴 확산 적용. 현업 만족도 향상.

**[기술적 의사결정]**
- 운영팀·유관 부서 인터뷰 주도하여 가장 큰 병목(어드민 접속 → 데이터 확인 → 메신저 공유의 컨텍스트 스위칭) 발굴
- Slack 선택: 구성원이 가장 익숙한 플랫폼으로 채택률 극대화, 별도 앱 설치 없이 즉시 도입
- Event API + Interactive Component: 컨텍스트 스위칭 제거로 업무 효율 극대화

---

### AI 기반 개발 생산성 혁신 (2024.03 - 현재)

**역할**: AI 도구 도입 및 활용 프로세스 구축 주도 (1인 리딩)

**Tech Stack**: Claude Code, MCP (Atlassian/Confluence), API Documentation Automation

**[프로젝트 배경]**
반복적인 운영 도구 개발과 문서화 작업에 많은 시간이 소요되고 있었습니다. 특히 API 문서 작성 및 최신화, JIRA 티켓 정리, Confluence 문서화 등 부가 업무가 핵심 개발 시간을 잠식하고 있었습니다. 문서 최신화 지연으로 클라이언트 협업 비효율도 발생하고 있었습니다.

**[주요 성과]**
- **운영 도구 개발 시간 90% 단축 (10시간 → 1시간)**: Claude Code를 활용하여 반복적인 CRUD 기반 운영 도구, 배치 스크립트, 데이터 마이그레이션 도구 등을 신속하게 개발. 보일러플레이트 코드 생성 자동화.
- **API 문서화 업무 90% 자동화**: Atlassian MCP를 활용하여 JIRA 티켓 작업 완료 후 해당 작업 Git Branch에서 MCP를 통해 Confluence에 API 문서 자동 생성. 작업 컨텍스트를 유지한 채 문서화하여 정보 손실 방지.
- **클라이언트 협업 효율화**: 표준 API 문서 템플릿 정의로 Request/Response 예시, 에러 코드 정의까지 포함된 완성도 높은 문서를 즉시 제공. 커뮤니케이션 비용 절감.
- **팀 내 AI 도구 활용 문화 전파**: 효과적인 프롬프트 패턴과 활용 사례를 팀 내 공유하여 다른 개발자들의 AI 도구 적응 지원.

**[기술적 의사결정]**
- AI Agent(Claude Code) + MCP 도입: 자연어 명령으로 운영 도구 개발 90% 시간 단축, Atlassian 연동으로 문서화 자동화
- 표준 API 문서 템플릿 정의: 일관된 포맷으로 클라이언트와의 커뮤니케이션 비용 절감

---

### 개발 문화 및 시스템 안정성 강화 (2022.02 - 현재)

**역할**: 개발 프로세스 개선 주도 및 모니터링 체계 구축

**Tech Stack**: Elasticsearch, Elastic APM, TDD (JUnit, Mockito), GitHub PR Review, Slack API, Shell Script

**[주요 성과]**
- **검색 API TPS 1500% 향상 (200 → 3,000)**: Elasticsearch Hit Index Count 알고리즘 분석 및 병목 지점 파악. 인덱싱 전략 재설계로 트래픽 대응력 15배 확보.
- **Review API Latency 90% 개선 (4,000ms → 80ms)**: 객체화 구조 채용으로 유지보수성 향상. Slow Query 분석 후 인덱스 최적화로 사용자 응답 속도 대폭 개선.
- **TDD 기반 개발 도입**: 신규 기능 개발 시 TDD 적용, 테스트 코드 작성 문화 정착. 핵심 비즈니스 로직에 대한 단위 테스트 커버리지 확보로 배포 후 버그·핫픽스 건수 감소.
- **PR 기반 코드 리뷰 프로세스 정착**: 배포 전 최소 2인 승인 의무화로 코드 품질 향상. 단순 지적보다 '더 나은 설계'를 논의하는 문화 조성으로 팀원 참여 유도.
- **Slow Query 모니터링 체계 구축**: Elastic APM 기반 2초+ 쿼리 자동 추출 및 최적화 프로세스 확립. 인덱스 누락, 불필요한 테이블 조인 식별 후 최적화.
- **서버 리소스 모니터링 구축**: 디스크/메모리 사용량 체크 스크립트 구성 → 임계치 초과 시 Slack 알림 자동 발송. 장애 발생 전 선제적 대응.
- **코드 컨벤션 명문화**: 팀원들과의 협의를 통해 Java/Spring 코딩 컨벤션 문서화. 신규 입사자 온보딩 시간 단축.

---

### (주)인터파크
**Backend Developer** | 2021.09 - 2022.01 (5개월)

---

### 레거시 시스템 TDD 도입 및 테스트 문화 정착

**역할**: 백엔드 개발자

**Tech Stack**: Java, Spring Framework, Oracle, JUnit, Mockito

**[프로젝트 배경]**
레거시 시스템에 테스트 코드가 전무하여 기능 변경 시 사이드 이펙트 파악이 불가능했습니다. 판매자 정산/주문 조회 등 핵심 기능의 정합성 검증 수단이 없었고, 코드 수정 시 수동 테스트에 의존하여 배포 리스크가 증가하고 개발 속도가 저하되고 있었습니다.

**[주요 성과]**
- **TDD 도입 및 테스트 커버리지 확보**: 신규 기능 개발부터 TDD 방식 적용, 핵심 비즈니스 로직(Seller 아이템 조회, 주문 관련 통합 데이터 조회)에 단위 테스트 작성으로 변경 안정성 확보.
- **테스트 문화 정착**: 테스트 작성 가이드 공유 및 코드 리뷰 시 테스트 코드 포함 여부 검토 프로세스 도입. 팀 내 TDD 기반 개발 방식 정착.
- **코드 리팩토링**: 테스트 가능한 구조로 복잡한 비즈니스 로직을 Service Layer로 분리하여 유지보수 효율 개선.

---

### (주)한국문헌정보기술
**Backend Developer** | 2018.06 - 2021.08 (3년 2개월)

---

### 자체 검색 엔진 구축 및 대용량 처리 최적화

**역할**: 검색 엔진 아키텍처 설계 및 대용량 처리 최적화 주도

**Tech Stack**: Java, Spring Framework, Elasticsearch, Nori Analyzer, Apache Tika, Oracle

**[프로젝트 배경]**
솔루션 납품에 필요한 상용 검색엔진 라이선스 비용이 수천만원에 달하여 전체 프로젝트 비용 상승. 솔루션 납품 이후 초기 데이터 구축 시 대량 기록물 이미지 등록에 단건 Insert 방식으로 처리 시간 최소 10시간 이상 소요되고 있었습니다.

**[주요 성과]**
- **라이선스 비용 수천만원 절감**: Elasticsearch + Nori 한글 형태소 분석기 기반 자체 검색 엔진을 구축하여 상용 솔루션 대체. Apache Tika 플러그인 활용하여 PDF, DOCX 등 다양한 문서 형식 색인 지원.
- **데이터 등록 속도 70% 단축 (10시간 → 3시간)**: Bulk Insert 전환으로 DB 트랜잭션 횟수 최소화. 이미지 1개당 다양한 유형의 썸네일(2000px, 1000px, 700px, 500px, 300px) 구성 시 가장 큰 해상도 썸네일 생성 후 나머지를 병렬 처리하여 리소스 절감. 비동기 처리 도입으로 전체 처리 속도 개선.
- **2021년 사내 우수사원 선정**: 대용량 처리 최적화 및 검색 엔진 구축 성과로 수상.

---

## Education

**대전대학교** | 컴퓨터공학 학사 (2011.02 - 2018.02)

---

## Certifications

**정보처리기사** | 한국산업인력공단 | 2017.05

---

## Awards

**2021년 사내 우수사원** | (주)한국문헌정보기술
