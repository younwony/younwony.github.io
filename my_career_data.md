# 윤원희 - 이력 및 경력 데이터

> 이 파일은 이력서 및 경력기술서의 모든 내용을 통합한 데이터 소스입니다.
> 이력서 개선 요청 시 이 파일의 내용을 참고하여 수정합니다.

---

# 개인 정보

- **이름:** 윤원희
- **직무:** Backend Developer (7년 차)
- **이메일:** wony9324@naver.com
- **전화번호:** 010-3555-2320
- **GitHub:** https://github.com/younwony

---

# Professional Summary

**"시스템 안정성과 데이터 가치를 모두 잡는 백엔드 개발자"**

Java/Spring 기반의 SI/SM 및 커머스 도메인에서 7년간 상품·전시·주문 등 핵심 비즈니스 로직을 개발하고 운영하며 탄탄한 기본기를 쌓았습니다. 이러한 안정적인 시스템 구축 역량을 바탕으로, 최근 마케팅 도메인으로 영역을 확장하여 200만 건 규모의 대용량 데이터 파이프라인을 성공적으로 구축했습니다.

단순 기능 구현을 넘어 레거시 시스템 개선과 쿼리 튜닝에 강점이 있으며, 최근에는 병렬 처리 및 Scale-out 설계를 도입해 검색 성능 최적화와 업무 자동화를 주도하며 데이터 처리 속도를 100배(100h→1h) 개선하고 'Zero Ops' 환경을 구축하여 조직의 생산성을 혁신하는 데 기여하고 있습니다.

---

# Core Competencies

- #### Architecture & Performance: 대용량 데이터 처리를 위한 병렬 아키텍처 설계 및 Scale-out 경험 보유
- #### Data Pipeline: 200만 건 이상의 이기종 데이터 수집·정제·적재(ETL) 파이프라인 구축
- #### Legacy Refactoring: 복잡한 비즈니스 로직 개선 및 고성능 쿼리 튜닝을 통한 시스템 안정화
- #### Search Engine: Elasticsearch 기반의 검색 엔진 도입 및 인덱싱 최적화
- #### Automation: 운영 비효율 제거를 위한 업무 프로세스 100% 자동화 (Zero Ops 지향)

---
# Technical Skills

### Languages/Frameworks
- Java
- Spring Boot
- JPA/Hibernate

### Database & Cache
- MySQL
- Oracle
- Redis
- Elasticsearch

### Infra & DevOps
- AWS (EC2, S3, RDS)
- Jenkins
- GitHub Actions

### Tools
- IntelliJ
- JIRA
- Confluence
- Slack API
- GA4
- BigQuery

---

## Work Experience

### (주)구하다

**기간:** 2022.02 - 재직 중 (3년 9개월)

**부서:** Tech 팀

**역할:** 백엔드 개발자 (Senior Backend Developer)

#### 프로젝트 1: 인플루언서 데이터 플랫폼 고도화 (200만 데이터 규모)

**📌 Situation (배경):**
- **수작업 의존**: 마케팅팀이 틱톡/인스타그램을 직접 탐색하고 엑셀(Excel)에 수기로 입력하여 관리함에 따라 인적 리소스 한계 및 데이터 최신성 유지 불가.
- **캠페인 확장 불가**: 하루에 수집 가능한 인플루언서가 수십 명 수준에 불과해 대형 캠페인 진행 및 다양한 인플루언서 매칭이 불가능
- **데이터 파편화**: 여러 플랫폼의 지표를 통합적으로 분석할 기준이 없어 정량적 성과 측정이 어려움.

**🎯 Task (과제/목표):**
- 수집 프로세스 100% 자동화 및 정밀 타겟팅(이메일 보유, US 거주 등)으로 인플루언서를 수집 
- CDN 링크 만료로 인한 이미지 유실을 99% 처리하여 데이터의 정합성 확보
- 200만 건 규모의 실시간 검색 및 분석 기능 제공
- 리포팅 자동화: Google Sheets API를 활용하여 리포팅 작업을 자동화하고, 마케팅 캠페인에 필요한 성과 데이터를 실시간으로 업데이트.

**⚡ Action (해결 방법):**
- 수집 프로세스 100% 자동화: 기존의 수작업 기반 수집 방식을 완전히 자동화하여, API(TikTok API, Ensemble API, EchoTik API 등)와 Web Scraper 크롤링을 통해 정밀 타겟팅된 인플루언서 데이터를 자동으로 수집. 수집 조건에 맞춰 이메일 보유, US 거주 등 다양한 필터링을 통해 정확한 데이터를 확보.
- 단순 재시도 로직 구현: API 요청 중 오류 발생 시, 고정된 시간 간격으로 재시도를 진행하는 방식으로 Retry 로직을 설계하여 API 차단을 피하고, 실패 시 자동으로 복구되도록 처리.
- 분산 제어: Redis Distributed Lock을 도입하여 멀티 인스턴스 환경에서 중복 수집을 방지하고 데이터 정확성 유지.
- 검색 엔진 최적화: Elasticsearch를 도입하여 복합 조건 검색(플랫폼, 팔로워 수, 지역 등)을 200ms 이내로 처리하여 실시간 검색 및 분석 성능 개선.
- 리포팅 자동화: Google Sheets API를 활용하여 리포팅 작업을 완전히 자동화하고, 실시간으로 캠페인 성과 데이터를 추적 및 관리.

**✅ Result (성과):**
- 데이터 수집의 100% 자동화 및 정밀 타겟팅을 통해 일 5,000명의 인플루언서를 자동 수집.
- 캠페인 확장성 향상 및 다양한 인플루언서를 캠페인에 적용 가능하게 되어 마케팅 효율성 증가.
- 200만 건 규모의 데이터를 실시간으로 처리하며, 이미지 유실 제로를 달성하여 데이터 정합성 확보.
- 리포팅 작업 완전 자동화로 운영팀 수작업 제거

**사용 기술:**
- Spring Boot, Redis Lock, Elasticsearch, Google Sheets API

---

#### 프로젝트 2: 네이버 쇼핑 최저가 대응 및 동적 가격(Dynamic Pricing) 시스템

**📌 Situation (배경):**

- 비즈니스 니즈: 매출 비중 1위 채널인 '네이버 쇼핑'의 노출 우위를 점하기 위해 가격비교 그룹 내 최저가 진입이 필수적이었으나, 수동 대응으로는 경쟁 속도를 따라갈 수 없었음.
- 기술적 제약: 네이버 API의 일일 호출 한도(25,000 Call)와 엄격한 속도 제한으로 인해, 전체 상품에 대한 실시간 대응이 불가능한 딜레마 발생.

**🎯 Task (과제/목표):**

- API 제약 극복: 한정된 API 리소스(Quota) 내에서 매출 기여도가 높은 핵심 상품을 선별하여 최저가를 방어하는 알고리즘 구현.
- 동적 가격 정책 수립: 무조건적인 최저가가 아닌, 마진율을 보장하는 범위(4% 이내) 내에서만 가격을 조정하는 안전장치 마련.
- 하이브리드 프로세스 설계: 시스템이 처리하지 못하는 예외 케이스(Missing Data)를 MD팀이 수동으로 처리할 수 있도록 **'자동+매뉴얼 하이브리드 운영 구조'**를 직접 설계하고 리딩.

**⚡ Action (해결 방법):**

- Dynamic Pricing 로직 구현: 모델번호 매핑을 통해 경쟁사 최저가를 수집하고, [자사 판매가 vs 최저가 차이 < 4%] & [최소 마진 확보] 조건을 만족할 때만 할인율을 자동 적용하는 로직 개발.
 API Quota 효율화 (Scheduling): 일 25,000건의 호출 한도 내에서 최대 성과를 내기 위해, 매출 상위 및 노출 중요 상품을 우선순위로 스케줄링하여 API 활용도 극대화.
- 협업 프로세스 주도 (Process Design):마케팅/MD팀과 협의하여 '가격 추종 범위(4%)' 및 '예외 상품군' 정책을 확정.
 최저가 조회 실패나 매칭 오류 건을 별도 Admin 뷰로 제공하여, MD팀이 예외 케이스만 집중 관리할 수 있도록 업무 플로우 설계.
- 성과 검증 환경 구축: 가격 조정 이력을 로그화하고 GA/BigQuery와 연동하여, 가격 정책 적용 전후의 트래픽 및 매출 변화를 정량적으로 분석할 수 있는 환경 마련.

**✅ Result (성과):**
- 
- 매출/트래픽 10% 동반 상승: 가격 경쟁력 확보를 통해 해당 상품군의 매출과 유입 트래픽이 각각 10%씩 증가함을 데이터로 검증.
- 운영 효율 혁신: 단순 반복 업무는 시스템이 전담하고, 운영팀은 전략 상품 및 예외 케이스에만 집중하는 고효율 구조 정착.
- 비즈니스 리딩: 단순 기능 개발을 넘어 API 제약 사항을 비즈니스 규칙(우선순위)과 운영 프로세스(협업)로 풀어내는 주도적 역할 수행.

**사용 기술:**
Spring Batch, Naver Shopping API, BigQuery, Google Analytics

---

#### 프로젝트 3: 데이터 기반 프로세스 최적화 및 ChatOps 자동화

**📌 Situation (배경):**
- 파트너사의 잦은 품절과 수동 발주 처리로 인해 운영팀 업무의 40%가 단순 반복 작업에 소모됨
- 데이터가 아닌 '감'에 의존하여 클레임 원인 파악이 불가능했음
- 상품 이미지 변경 감지를 위해 전체 파일(수 MB)을 비교하여 AWS 비용 과다 발생

**🎯 Task (과제/목표):**
- **운영팀의 개입이 전혀 없는 'Zero Ops' 환경 구축**
- 로그 데이터를 기반으로 품절 리스크를 사전에 탐지하는 모니터링 체계 마련
- 이미지 비교 비용을 80% 이상 절감하면서도 정확도 유지

**⚡ Action (해결 방법):**
- **데이터 파이프라인:** GA4(행동 로그)와 DB(주문 로그)를 BigQuery로 통합 적재하여 '상습 품절 패턴' 분석 쿼리 작성, 데이터 기반 페널티 정책 수립
- **비용 최적화:** 이미지 전체(수 MB) 대신 Header(4KB) 해시 비교로 변경 감지 알고리즘 개선, S3 다운로드 비용 80% 절감
- **프로세스 통합:** Slack Event API를 활용해 메신저 내에서 '승인/반려' 버튼 클릭만으로 업무가 종결되도록 ChatOps 구현

**✅ Result (성과):**
- 전체 **품절률 20% 감소** 및 클레임 사전 차단
- 이미지 처리 비용 **80% 절감** (전체 파일 → Header 비교)
- 운영팀 반복 업무 **100% 제거**로 고부가가치 업무 집중 환경 마련

**사용 기술:**
- BigQuery, GA4, Slack Event API, AWS S3, Image Hashing

---

### (주)인터파크
**기간:** 2021.09 - 2022.01 (5개월)
**부서:** 쇼핑 개발팀
**역할:** 판매자 어드민 시스템 개발 및 유지보수

#### 프로젝트: Seller 어드민 성능 개선 및 레거시 리팩토링

**📌 Situation (배경):**
- 판매자 정산/주문 조회 시 Slow Query로 인한 응답 지연(5초 이상)
- 레거시 비즈니스 로직의 복잡도로 인한 유지보수 어려움

**⚡ Action (해결 방법):**
- **쿼리 최적화:** 실행 계획 분석을 통한 인덱스 튜닝 및 불필요한 JOIN 제거
- **코드 리팩토링:** 복잡한 비즈니스 로직을 Service Layer로 분리하여 가독성 향상

---

### (주)한국문헌정보기술
**기간:** 2018.06 - 2021.08 (3년 2개월)
**부서:** 솔루션 개발팀
**역할:** 공공기관 기록물 관리 솔루션 SI/SM

#### 프로젝트: 자체 검색 엔진 구축 및 대용량 처리 최적화

**📌 Situation (배경):**
- 기존 상용 검색 솔루션의 높은 라이선스 비용 부담
- 대량 기록물 이미지 등록 시 단건 Insert로 인한 처리 지연

**🎯 Task (과제/목표):**
- 비용 절감을 위한 자체 검색 엔진 구축 및 한글 검색 정확도 확보
- 대량 이미지 등록 속도 70% 이상 단축

**⚡ Action (해결 방법):**
- **검색 엔진 구축:** Elasticsearch 기반 자체 검색 엔진 개발, Nori 한글 형태소 분석기 적용으로 검색 정확도 향상
- **성능 최적화:** 단건 Insert를 Bulk Insert 알고리즘으로 전환하여 DB 트랜잭션 횟수 최소화

**✅ Result (성과):**
- 데이터 등록 속도 **70% 단축**
- 라이선스 비용 절감 및 검색 커스터마이징 자유도 확보
- **2021년 사내 우수사원** 선정

**사용 기술:**
- Elasticsearch, Nori Analyzer, Bulk Insert, Oracle

---

## Education

**대전대학교**
- 전공: 컴퓨터공학 학사
- 기간: 2011.02 - 2018.02

---

## Certifications

**정보처리기사**
- 발급기관: 한국산업인력공단
- 취득일: 2017.05

---

## Awards

**2021년 사내 우수사원**
- 회사: (주)한국문헌정보기술
- 연도: 2021
- 사유: 대용량 처리 최적화 및 검색 엔진 구축 성과

---

## 업데이트 가이드

이 파일에 새로운 경력이나 프로젝트를 추가할 때는 다음 형식을 따라주세요:

### 프로젝트 추가 시 형식 (STAR 기법)

```markdown
#### 프로젝트: [프로젝트명]

**📌 Situation (배경):**
- 당시 상황 및 문제점 설명

**🎯 Task (과제/목표):**
- 해결해야 할 목표 (구체적 수치 포함)

**⚡ Action (해결 방법):**
- 본인이 수행한 핵심 역할
- 기술적 의사결정 및 적용 기술

**✅ Result (성과):**
- 정량적 수치로 표현된 성과

**사용 기술:**
- 기술스택 나열
```

### 회사 경력 추가 시 형식

```markdown
### [회사명]
**기간:** YYYY.MM - YYYY.MM (N년 N개월)
**부서:** 부서명
**역할:** 담당 역할
```
