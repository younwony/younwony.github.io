# 윤원희 - 이력 및 경력 데이터

> 이 파일은 이력서 및 경력기술서의 모든 내용을 통합한 데이터 소스입니다.
> 이력서 개선 요청 시 이 파일의 내용을 참고하여 수정합니다.

---

# 개인 정보

- **이름:** 윤원희
- **직무:** Backend Developer (7년 차)
- **이메일:** wony9324@naver.com
- **전화번호:** 010-3555-2320
- **GitHub:** https://github.com/younwony

---

# Professional Summary

**"시스템 안정성과 데이터 가치를 모두 잡는 백엔드 개발자"**

Java/Spring 기반의 SI/SM 및 커머스 도메인에서 7년간 상품·전시·주문 등 핵심 비즈니스 로직을 개발하고 운영하며 탄탄한 기본기를 쌓았습니다. 이러한 안정적인 시스템 구축 역량을 바탕으로, 최근 마케팅 도메인으로 영역을 확장하여 200만 건 규모의 대용량 데이터 파이프라인을 성공적으로 구축했습니다.

단순 기능 구현을 넘어 레거시 시스템 개선과 쿼리 튜닝에 강점이 있으며, 최근에는 병렬 처리 및 Scale-out 설계를 도입해 검색 성능 최적화와 업무 자동화를 주도하며 데이터 처리 속도를 100배(100h→1h) 개선하고 'Zero Ops' 환경을 구축하여 조직의 생산성을 혁신하는 데 기여하고 있습니다.

---

# Core Competencies

- #### Architecture & Performance: 대용량 데이터 처리를 위한 병렬 아키텍처 설계 및 Scale-out 경험 보유
- #### Data Pipeline: 200만 건 이상의 이기종 데이터 수집·정제·적재(ETL) 파이프라인 구축
- #### Legacy Refactoring: 복잡한 비즈니스 로직 개선 및 고성능 쿼리 튜닝을 통한 시스템 안정화
- #### Search Engine: Elasticsearch 기반의 검색 엔진 도입 및 인덱싱 최적화
- #### Automation: 운영 비효율 제거를 위한 업무 프로세스 100% 자동화 (Zero Ops 지향)

---
# Technical Skills

### Languages/Frameworks
- Java
- Spring Boot
- JPA/Hibernate

### Database & Cache
- MySQL
- Oracle
- Redis
- Elasticsearch

### Infra & DevOps
- AWS (EC2, S3, RDS)
- Jenkins
- GitHub Actions

### Tools
- IntelliJ
- JIRA
- Confluence
- Slack API
- GA4
- BigQuery

---

## Work Experience

### (주)구하다

**기간:** 2022.02 - 재직 중 (3년 9개월)

**부서:** Tech 팀

**역할:** 백엔드 개발자 (Senior Backend Developer)

#### 프로젝트 1: 인플루언서 데이터 플랫폼 고도화 (200만 데이터 규모)

**📌 Situation (배경):**
- **수작업 의존**: 마케팅팀이 틱톡/인스타그램을 직접 탐색하고 엑셀(Excel)에 수기로 입력하여 관리함에 따라 인적 리소스 한계 및 데이터 최신성 유지 불가.
- **캠페인 확장 불가**: 하루에 수집 가능한 인플루언서가 수십 명 수준에 불과해 대형 캠페인 진행 및 다양한 인플루언서 매칭이 불가능
- **데이터 파편화**: 여러 플랫폼의 지표를 통합적으로 분석할 기준이 없어 정량적 성과 측정이 어려움.

**🎯 Task (과제/목표):**
- 수집 프로세스 100% 자동화 및 정밀 타겟팅(이메일 보유, US 거주 등)으로 인플루언서를 수집 
- CDN 링크 만료로 인한 이미지 유실을 99% 처리하여 데이터의 정합성 확보
- 200만 건 규모의 실시간 검색 및 분석 기능 제공
- 리포팅 자동화: Google Sheets API를 활용하여 리포팅 작업을 자동화하고, 마케팅 캠페인에 필요한 성과 데이터를 실시간으로 업데이트.

**⚡ Action (해결 방법):**
- 수집 프로세스 100% 자동화: 기존의 수작업 기반 수집 방식을 완전히 자동화하여, API(TikTok API, Ensemble API, EchoTik API 등)와 Web Scraper 크롤링을 통해 정밀 타겟팅된 인플루언서 데이터를 자동으로 수집. 수집 조건에 맞춰 이메일 보유, US 거주 등 다양한 필터링을 통해 정확한 데이터를 확보.
- 단순 재시도 로직 구현: API 요청 중 오류 발생 시, 고정된 시간 간격으로 재시도를 진행하는 방식으로 Retry 로직을 설계하여 API 차단을 피하고, 실패 시 자동으로 복구되도록 처리.
- 분산 제어: Redis Distributed Lock을 도입하여 멀티 인스턴스 환경에서 중복 수집을 방지하고 데이터 정확성 유지.
- 검색 엔진 최적화: Elasticsearch를 도입하여 복합 조건 검색(플랫폼, 팔로워 수, 지역 등)을 200ms 이내로 처리하여 실시간 검색 및 분석 성능 개선.
- 리포팅 자동화: Google Sheets API를 활용하여 리포팅 작업을 완전히 자동화하고, 실시간으로 캠페인 성과 데이터를 추적 및 관리.

**✅ Result (성과):**
- 데이터 수집의 100% 자동화 및 정밀 타겟팅을 통해 일 5,000명의 인플루언서를 자동 수집.
- 캠페인 확장성 향상 및 다양한 인플루언서를 캠페인에 적용 가능하게 되어 마케팅 효율성 증가.
- 200만 건 규모의 데이터를 실시간으로 처리하며, 이미지 유실 제로를 달성하여 데이터 정합성 확보.
- 리포팅 작업 완전 자동화로 운영팀 수작업 제거

**사용 기술:**
- Spring Boot, Redis Lock, Elasticsearch, Google Sheets API

---

#### 프로젝트 2: 네이버 쇼핑 최저가 대응 및 동적 가격(Dynamic Pricing) 시스템

**📌 Situation (배경):**
- 수백만 건의 상품 데이터에서 경쟁사 최저가를 실시간으로 비교해야 했으나, RDB 쿼리 성능 저하로 업데이트가 6시간 이상 지연됨
- 수동 가격 변경 프로세스로 인해 경쟁 상품 대응이 24시간 이상 소요되어 매출 기회 손실

**🎯 Task (과제/목표):**
- **가격 비교 조회 속도를 ms 단위로 단축하여 실시간 대응 체계 구축**
- 대규모 배치 작업 중에도 DB 부하를 최소화하여 서비스 안정성 유지
- 마진율을 고려한 자동 가격 조정으로 수익성 보장

**⚡ Action (해결 방법):**
- **저장소 전환:** 복합 조건 검색(브랜드+모델)에 유리한 Elasticsearch를 도입하여 역색인 구조 활용, 검색 성능 **20배 개선**
- **배치 최적화:** Spring Batch의 Chunk 사이즈를 튜닝하고, 병렬 스텝(Parallel Step)을 적용해 대량 트랜잭션 처리 시간을 단축
- **API 안정성:** Resilience4j RateLimiter 및 Exponential Backoff 정책으로 네이버 쇼핑 API 호출 제어

**✅ Result (성과):**
- 가격 대응 속도 실시간(Real-time) 수준으로 개선
- 가격 경쟁력 확보를 통해 **매출 10% 증대** 및 유입 트래픽 **15% 상승**
- 운영팀 수동 업무 완전 제거 (Zero Ops)

**사용 기술:**
- Spring Batch, Elasticsearch, Resilience4j, Naver Shopping API

---

#### 프로젝트 3: 데이터 기반 프로세스 최적화 및 ChatOps 자동화

**📌 Situation (배경):**
- 파트너사의 잦은 품절과 수동 발주 처리로 인해 운영팀 업무의 40%가 단순 반복 작업에 소모됨
- 데이터가 아닌 '감'에 의존하여 클레임 원인 파악이 불가능했음
- 상품 이미지 변경 감지를 위해 전체 파일(수 MB)을 비교하여 AWS 비용 과다 발생

**🎯 Task (과제/목표):**
- **운영팀의 개입이 전혀 없는 'Zero Ops' 환경 구축**
- 로그 데이터를 기반으로 품절 리스크를 사전에 탐지하는 모니터링 체계 마련
- 이미지 비교 비용을 80% 이상 절감하면서도 정확도 유지

**⚡ Action (해결 방법):**
- **데이터 파이프라인:** GA4(행동 로그)와 DB(주문 로그)를 BigQuery로 통합 적재하여 '상습 품절 패턴' 분석 쿼리 작성, 데이터 기반 페널티 정책 수립
- **비용 최적화:** 이미지 전체(수 MB) 대신 Header(4KB) 해시 비교로 변경 감지 알고리즘 개선, S3 다운로드 비용 80% 절감
- **프로세스 통합:** Slack Event API를 활용해 메신저 내에서 '승인/반려' 버튼 클릭만으로 업무가 종결되도록 ChatOps 구현

**✅ Result (성과):**
- 전체 **품절률 20% 감소** 및 클레임 사전 차단
- 이미지 처리 비용 **80% 절감** (전체 파일 → Header 비교)
- 운영팀 반복 업무 **100% 제거**로 고부가가치 업무 집중 환경 마련

**사용 기술:**
- BigQuery, GA4, Slack Event API, AWS S3, Image Hashing

---

### (주)인터파크
**기간:** 2021.09 - 2022.01 (5개월)
**부서:** 쇼핑 개발팀
**역할:** 판매자 어드민 시스템 개발 및 유지보수

#### 프로젝트: Seller 어드민 성능 개선 및 레거시 리팩토링

**📌 Situation (배경):**
- 판매자 정산/주문 조회 시 Slow Query로 인한 응답 지연(5초 이상)
- 레거시 비즈니스 로직의 복잡도로 인한 유지보수 어려움

**⚡ Action (해결 방법):**
- **쿼리 최적화:** 실행 계획 분석을 통한 인덱스 튜닝 및 불필요한 JOIN 제거
- **코드 리팩토링:** 복잡한 비즈니스 로직을 Service Layer로 분리하여 가독성 향상

---

### (주)한국문헌정보기술
**기간:** 2018.06 - 2021.08 (3년 2개월)
**부서:** 솔루션 개발팀
**역할:** 공공기관 기록물 관리 솔루션 SI/SM

#### 프로젝트: 자체 검색 엔진 구축 및 대용량 처리 최적화

**📌 Situation (배경):**
- 기존 상용 검색 솔루션의 높은 라이선스 비용 부담
- 대량 기록물 이미지 등록 시 단건 Insert로 인한 처리 지연

**🎯 Task (과제/목표):**
- 비용 절감을 위한 자체 검색 엔진 구축 및 한글 검색 정확도 확보
- 대량 이미지 등록 속도 70% 이상 단축

**⚡ Action (해결 방법):**
- **검색 엔진 구축:** Elasticsearch 기반 자체 검색 엔진 개발, Nori 한글 형태소 분석기 적용으로 검색 정확도 향상
- **성능 최적화:** 단건 Insert를 Bulk Insert 알고리즘으로 전환하여 DB 트랜잭션 횟수 최소화

**✅ Result (성과):**
- 데이터 등록 속도 **70% 단축**
- 라이선스 비용 절감 및 검색 커스터마이징 자유도 확보
- **2021년 사내 우수사원** 선정

**사용 기술:**
- Elasticsearch, Nori Analyzer, Bulk Insert, Oracle

---

## Education

**대전대학교**
- 전공: 컴퓨터공학 학사
- 기간: 2011.02 - 2018.02

---

## Certifications

**정보처리기사**
- 발급기관: 한국산업인력공단
- 취득일: 2017.05

---

## Awards

**2021년 사내 우수사원**
- 회사: (주)한국문헌정보기술
- 연도: 2021
- 사유: 대용량 처리 최적화 및 검색 엔진 구축 성과

---

## 업데이트 가이드

이 파일에 새로운 경력이나 프로젝트를 추가할 때는 다음 형식을 따라주세요:

### 프로젝트 추가 시 형식 (STAR 기법)

```markdown
#### 프로젝트: [프로젝트명]

**📌 Situation (배경):**
- 당시 상황 및 문제점 설명

**🎯 Task (과제/목표):**
- 해결해야 할 목표 (구체적 수치 포함)

**⚡ Action (해결 방법):**
- 본인이 수행한 핵심 역할
- 기술적 의사결정 및 적용 기술

**✅ Result (성과):**
- 정량적 수치로 표현된 성과

**사용 기술:**
- 기술스택 나열
```

### 회사 경력 추가 시 형식

```markdown
### [회사명]
**기간:** YYYY.MM - YYYY.MM (N년 N개월)
**부서:** 부서명
**역할:** 담당 역할
```
